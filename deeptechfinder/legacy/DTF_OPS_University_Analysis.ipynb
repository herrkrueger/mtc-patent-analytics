{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTechFinder University Patent Analysis Platform\n",
    "\n",
    "## Interactive Analysis of German University Patent Portfolios\n",
    "\n",
    "This comprehensive notebook provides an **interactive analysis platform** for exploring German university patent portfolios using EPO's DeepTechFinder data enriched with detailed bibliographic information from EPO OPS API.\n",
    "\n",
    "### Key Features\n",
    "- **Interactive University Selection** - Choose from 100 German universities with sortable options\n",
    "- **Comprehensive Patent Analysis** - Complete bibliographic data enrichment via EPO OPS\n",
    "- **Advanced Collaboration Mapping** - Industry partnerships and research networks\n",
    "- **Priority Patent Family Analysis** - Strategic filing patterns and family relationships\n",
    "- **Professional PDF Reports** - Export-ready analysis documents\n",
    "- **CSV Data Exports** - Complete datasets for further analysis\n",
    "\n",
    "### Coverage\n",
    "- **100 German Universities** with 11,118 total patent applications\n",
    "- **4,907 granted patents** analyzed across all institutions\n",
    "- **1.8M+ students** represented across the university system\n",
    "- **Real-time EPO OPS integration** for up-to-date patent intelligence\n",
    "\n",
    "### Target Users\n",
    "- **Patent Information Professionals** - Enhanced due diligence and FTO analysis\n",
    "- **PATLIB Staff** - University patent portfolio intelligence\n",
    "- **Technology Transfer Offices** - Strategic partnership identification\n",
    "- **Research Institutions** - Competitive analysis and collaboration opportunities\n",
    "- **Patent Attorneys** - Comprehensive prior art and inventor network mapping\n",
    "\n",
    "### Methodology Validation\n",
    "Based on proven analysis frameworks demonstrated with **TU Dresden** (265 patents) and **University of Applied Sciences Saarbr√ºcken** portfolios, with **100% EPO OPS retrieval success rates** and **complete bibliographic enrichment**.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to explore German university innovation? Start with the interactive university selector below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading German University Patent Data...\n",
      "‚úÖ Loaded data for 100 German universities\n",
      "üìà Total students: 1,789,466\n",
      "üìÑ Total applications: 11,118\n",
      "üèÜ Total granted patents: 4,907\n",
      "\n",
      "üéØ University data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load university data and create interactive selector\n",
    "print(\"üìä Loading German University Patent Data...\")\n",
    "\n",
    "# Load university statistics from pre-processed data\n",
    "try:\n",
    "    with open('./output/university_analysis.json', 'r') as f:\n",
    "        university_data = json.load(f)\n",
    "    \n",
    "    # Get universities list and create sorted versions\n",
    "    universities_list = university_data['universities']\n",
    "    \n",
    "    # Create different sorting options\n",
    "    universities_by_applications = sorted(universities_list, key=lambda x: x['total_applications'], reverse=True)\n",
    "    universities_by_students = sorted(universities_list, key=lambda x: x['total_students'], reverse=True)\n",
    "    universities_by_granted = sorted(universities_list, key=lambda x: x['granted_patents'], reverse=True)\n",
    "    universities_by_grant_rate = sorted(universities_list, key=lambda x: x['grant_rate'], reverse=True)\n",
    "    universities_alphabetical = sorted(universities_list, key=lambda x: x['name'])\n",
    "    \n",
    "    # Store all sorting options for widget use\n",
    "    university_data_sorted = {\n",
    "        'by_applications': universities_by_applications,\n",
    "        'by_students': universities_by_students,\n",
    "        'by_granted': universities_by_granted,\n",
    "        'by_grant_rate': universities_by_grant_rate,\n",
    "        'alphabetical': universities_alphabetical\n",
    "    }\n",
    "    \n",
    "    universities_sorted = universities_by_applications  # Default to applications sorting\n",
    "    \n",
    "    print(f\"‚úÖ Loaded data for {len(universities_sorted)} German universities\")\n",
    "    print(f\"üìà Total students: {sum(u['total_students'] for u in universities_sorted):,}\")\n",
    "    print(f\"üìÑ Total applications: {sum(u['total_applications'] for u in universities_sorted):,}\")\n",
    "    print(f\"üèÜ Total granted patents: {sum(u['granted_patents'] for u in universities_sorted):,}\")\n",
    "    \n",
    "    # Create university selection options\n",
    "    university_options = [(f\"{u['name']} ({u['total_applications']} patents, {u['total_students']:,} students)\", u['name']) \n",
    "                         for u in universities_sorted]\n",
    "    \n",
    "    print(\"\\nüéØ University data loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå University data not found. Please run university analysis first.\")\n",
    "    print(\"üí° Run: python ./scripts/analyze_universities.py\")\n",
    "    university_options = []\n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Unexpected data structure in university_analysis.json: {e}\")\n",
    "    print(\"üí° The file may need to be regenerated with: python ./scripts/analyze_universities.py\")\n",
    "    university_options = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create interactive university selection interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéõÔ∏è INTERACTIVE UNIVERSITY ANALYSIS PLATFORM\n",
      "=============================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>üìã Step 1: Select University and Analysis Options</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a8e61dbb984187ad0124baf6ff9971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Sort by:', options=(('By Patent Applications (High to Low)‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_university_selector():\n",
    "    \"\"\"Create interactive widgets for university selection with sorting options\"\"\"\n",
    "    \n",
    "    # Sorting options\n",
    "    sort_dropdown = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('By Patent Applications (High to Low)', 'by_applications'),\n",
    "            ('By Student Count (High to Low)', 'by_students'),\n",
    "            ('By Granted Patents (High to Low)', 'by_granted'),\n",
    "            ('By Grant Rate (High to Low)', 'by_grant_rate'),\n",
    "            ('Alphabetical (A-Z)', 'alphabetical')\n",
    "        ],\n",
    "        value='by_applications',\n",
    "        description='Sort by:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # University dropdown (will be updated based on sorting)\n",
    "    university_dropdown = widgets.Dropdown(\n",
    "        options=university_options,\n",
    "        description='University:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "    \n",
    "    # Search box for filtering\n",
    "    search_box = widgets.Text(\n",
    "        placeholder='Type to search universities...',\n",
    "        description='Search:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    \n",
    "    # Analysis options\n",
    "    analysis_options = widgets.SelectMultiple(\n",
    "        options=[\n",
    "            ('Complete Patent Analysis (recommended)', 'complete'),\n",
    "            ('Priority Family Analysis', 'priority'),\n",
    "            ('Industry Collaboration Mapping', 'collaboration'),\n",
    "            ('Inventor Network Analysis', 'inventors'),\n",
    "            ('Technology Classification Review', 'technology')\n",
    "        ],\n",
    "        value=['complete', 'priority', 'collaboration'],\n",
    "        description='Analysis Type:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(height='120px', width='400px')\n",
    "    )\n",
    "    \n",
    "    # Number of patents to analyze (for performance)\n",
    "    patent_limit = widgets.IntSlider(\n",
    "        value=50,\n",
    "        min=10,\n",
    "        max=200,\n",
    "        step=10,\n",
    "        description='Patent Limit:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='d'\n",
    "    )\n",
    "    \n",
    "    # Generate PDF report option\n",
    "    generate_pdf = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Generate PDF Report',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Analysis button\n",
    "    analyze_button = widgets.Button(\n",
    "        description='üöÄ Start Analysis',\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='200px', height='40px'),\n",
    "        style={'font_weight': 'bold'}\n",
    "    )\n",
    "    \n",
    "    # Results output\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def update_university_list(change=None):\n",
    "        \"\"\"Update university dropdown based on sorting selection\"\"\"\n",
    "        sort_by = sort_dropdown.value\n",
    "        search_term = search_box.value.lower()\n",
    "        \n",
    "        # Get sorted university list\n",
    "        if sort_by in university_data_sorted:\n",
    "            sorted_unis = university_data_sorted[sort_by]\n",
    "        else:\n",
    "            sorted_unis = universities_sorted\n",
    "        \n",
    "        # Filter by search term if provided\n",
    "        if search_term:\n",
    "            filtered_unis = [u for u in sorted_unis if search_term in u['name'].lower()]\n",
    "        else:\n",
    "            filtered_unis = sorted_unis\n",
    "        \n",
    "        # Update dropdown options\n",
    "        new_options = [(f\"{u['name']} ({u['total_applications']} patents, {u['total_students']:,} students)\", u['name']) \n",
    "                      for u in filtered_unis]\n",
    "        \n",
    "        university_dropdown.options = new_options\n",
    "        if new_options:\n",
    "            university_dropdown.value = new_options[0][1]\n",
    "    \n",
    "    def on_analyze_clicked(button):\n",
    "        \"\"\"Handle analysis button click\"\"\"\n",
    "        selected_university = university_dropdown.value\n",
    "        selected_analyses = list(analysis_options.value)\n",
    "        max_patents = patent_limit.value\n",
    "        create_pdf = generate_pdf.value\n",
    "        \n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"üéØ Starting analysis for: {selected_university}\")\n",
    "            print(f\"üìä Analysis types: {', '.join(selected_analyses)}\")\n",
    "            print(f\"üìÑ Patent limit: {max_patents}\")\n",
    "            print(f\"üìã PDF Report: {'Yes' if create_pdf else 'No'}\")\n",
    "            print(\"\\n‚è≥ Analysis will begin in the next cell...\")\n",
    "            \n",
    "            # Store selections in global variables for use in analysis\n",
    "            global SELECTED_UNIVERSITY, SELECTED_ANALYSES, MAX_PATENTS, CREATE_PDF\n",
    "            SELECTED_UNIVERSITY = selected_university\n",
    "            SELECTED_ANALYSES = selected_analyses\n",
    "            MAX_PATENTS = max_patents\n",
    "            CREATE_PDF = create_pdf\n",
    "    \n",
    "    # Wire up event handlers\n",
    "    sort_dropdown.observe(update_university_list, names='value')\n",
    "    search_box.observe(update_university_list, names='value')\n",
    "    analyze_button.on_click(on_analyze_clicked)\n",
    "    \n",
    "    # Initial university list update\n",
    "    update_university_list()\n",
    "    \n",
    "    return {\n",
    "        'sort_dropdown': sort_dropdown,\n",
    "        'search_box': search_box,\n",
    "        'university_dropdown': university_dropdown,\n",
    "        'analysis_options': analysis_options,\n",
    "        'patent_limit': patent_limit,\n",
    "        'generate_pdf': generate_pdf,\n",
    "        'analyze_button': analyze_button,\n",
    "        'output': output\n",
    "    }\n",
    "\n",
    "if university_options:\n",
    "    widgets_dict = create_university_selector()\n",
    "    \n",
    "    # Display the interface\n",
    "    print(\"üéõÔ∏è INTERACTIVE UNIVERSITY ANALYSIS PLATFORM\")\n",
    "    print(\"=\" * 45)\n",
    "    display(HTML(\"<h3>üìã Step 1: Select University and Analysis Options</h3>\"))\n",
    "    \n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([widgets_dict['sort_dropdown'], widgets_dict['search_box']]),\n",
    "        widgets_dict['university_dropdown'],\n",
    "        widgets.HTML(\"<br><b>Analysis Configuration:</b>\"),\n",
    "        widgets.HBox([widgets_dict['analysis_options'], \n",
    "                     widgets.VBox([widgets_dict['patent_limit'], widgets_dict['generate_pdf']])]),\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        widgets_dict['analyze_button'],\n",
    "        widgets_dict['output']\n",
    "    ]))\n",
    "else:\n",
    "    print(\"‚ùå Cannot create university selector - data not available\")\n",
    "    print(\"üí° Please run: python ./scripts/analyze_universities.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING ANALYSIS FOR: Jacobs University Bremen\n",
      "============================================================\n",
      "üìä Analysis types: complete, priority, collaboration\n",
      "üìÑ Patent limit: 50\n",
      "üïê Started: 16:34:54\n",
      "üìÑ Found 35 patents for analysis\n",
      "‚úÖ EPO OPS authenticated (expires in 1199s)\n",
      "üîç Processing 1/35: EP05762942A\n",
      "‚úÖ Retrieved data for EP05762942A\n",
      "üîç Processing 2/35: EP06119771A\n",
      "‚úÖ Retrieved data for EP06119771A\n",
      "üîç Processing 3/35: EP07004710A\n",
      "‚úÖ Retrieved data for EP07004710A\n",
      "üîç Processing 4/35: EP06846983A\n",
      "‚úÖ Retrieved data for EP06846983A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 471\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Check if analysis was requested and run it\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECTED_UNIVERSITY\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[0;32m--> 471\u001b[0m     \u001b[43mperform_university_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ EPO OPS Analysis Module Loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[35], line 358\u001b[0m, in \u001b[0;36mperform_university_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Failed to retrieve data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Rate limiting - EPO OPS requirement\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä ANALYSIS COMPLETED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Successfully processed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuccessful_retrievals\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(university_patents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m patents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Complete EPO OPS Analysis Implementation\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from reportlab.lib.pagesizes import letter, A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.units import inch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Load EPO OPS credentials\n",
    "load_dotenv('../ipc-ops/.env')\n",
    "ops_key = os.getenv('OPS_KEY')\n",
    "ops_secret = os.getenv('OPS_SECRET')\n",
    "\n",
    "class EPOOPSClient:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"http://ops.epo.org/3.2/rest-services\"\n",
    "        self.auth_url = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "        self.consumer_key = ops_key\n",
    "        self.consumer_secret = ops_secret\n",
    "        self.access_token = None\n",
    "        \n",
    "    def get_access_token(self):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.auth_url,\n",
    "                data={'grant_type': 'client_credentials'},\n",
    "                auth=(self.consumer_key, self.consumer_secret),\n",
    "                headers={'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                token_data = response.json()\n",
    "                self.access_token = token_data['access_token']\n",
    "                print(f\"‚úÖ EPO OPS authenticated (expires in {token_data.get('expires_in', 'unknown')}s)\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ùå Authentication failed: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Authentication error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def format_patent_number(self, patent_number):\n",
    "        \"\"\"Format patent number for EPO OPS API calls\"\"\"\n",
    "        clean_number = patent_number.replace('EP', '').replace('A', '').replace('B', '')\n",
    "        \n",
    "        # Leading zero handling for different patent eras\n",
    "        if clean_number.startswith('0') and len(clean_number) == 8:\n",
    "            return clean_number  # Keep leading zero for 2000s patents\n",
    "        elif clean_number.startswith('00'):\n",
    "            return clean_number.lstrip('0')\n",
    "        else:\n",
    "            return clean_number.lstrip('0') if clean_number.lstrip('0') else clean_number\n",
    "            \n",
    "    def get_application_biblio(self, patent_number):\n",
    "        \"\"\"Get bibliographic data from EPO OPS API\"\"\"\n",
    "        if not self.access_token:\n",
    "            return None\n",
    "        \n",
    "        clean_number = self.format_patent_number(patent_number)\n",
    "        \n",
    "        # Try multiple formats\n",
    "        formats_to_try = [\n",
    "            f\"published-data/application/epodoc/EP{clean_number}/biblio\",\n",
    "            f\"published-data/application/epodoc/EP{clean_number.lstrip('0')}/biblio\"\n",
    "        ]\n",
    "        \n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {self.access_token}',\n",
    "            'Accept': 'application/json'  # CRITICAL: This was missing!\n",
    "        }\n",
    "        \n",
    "        for endpoint in formats_to_try:\n",
    "            url = f\"{self.base_url}/{endpoint}\"\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=15)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    return response.json()\n",
    "                elif response.status_code == 404:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ‚ùå Error {response.status_code} for {patent_number}\")\n",
    "                    return None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Request failed for {patent_number}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return None\n",
    "\n",
    "def extract_bibliographic_data(ops_data):\n",
    "    \"\"\"Extract structured data from EPO OPS response\"\"\"\n",
    "    if not ops_data:\n",
    "        return {}\n",
    "        \n",
    "    def find_recursive(data, target_keys):\n",
    "        \"\"\"Recursively find keys in nested structure\"\"\"\n",
    "        results = []\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                if any(target in key.lower() for target in target_keys):\n",
    "                    results.append(value)\n",
    "                results.extend(find_recursive(value, target_keys))\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                results.extend(find_recursive(item, target_keys))\n",
    "        return results\n",
    "    \n",
    "    extracted = {}\n",
    "    \n",
    "    # Extract applicants\n",
    "    applicant_data = find_recursive(ops_data, ['applicant'])\n",
    "    applicants = []\n",
    "    for app_section in applicant_data:\n",
    "        if isinstance(app_section, list):\n",
    "            for applicant in app_section:\n",
    "                if isinstance(applicant, dict) and 'applicant-name' in applicant:\n",
    "                    name_data = applicant['applicant-name']\n",
    "                    if isinstance(name_data, dict) and 'name' in name_data:\n",
    "                        name = name_data['name'].get('$', name_data['name'].get('#text', str(name_data['name'])))\n",
    "                        if isinstance(name, str) and name not in applicants:\n",
    "                            applicants.append(name)\n",
    "    \n",
    "    # Extract inventors\n",
    "    inventor_data = find_recursive(ops_data, ['inventor'])\n",
    "    inventors = []\n",
    "    for inv_section in inventor_data:\n",
    "        if isinstance(inv_section, list):\n",
    "            for inventor in inv_section:\n",
    "                if isinstance(inventor, dict) and 'inventor-name' in inventor:\n",
    "                    name_data = inventor['inventor-name']\n",
    "                    if isinstance(name_data, dict) and 'name' in name_data:\n",
    "                        name = name_data['name'].get('$', name_data['name'].get('#text', str(name_data['name'])))\n",
    "                        if isinstance(name, str) and name not in inventors:\n",
    "                            inventors.append(name)\n",
    "    \n",
    "    # Extract priority claims\n",
    "    priority_data = find_recursive(ops_data, ['priority-claim'])\n",
    "    priorities = []\n",
    "    for priority_section in priority_data:\n",
    "        if isinstance(priority_section, list):\n",
    "            for priority in priority_section:\n",
    "                if isinstance(priority, dict) and 'document-id' in priority:\n",
    "                    doc_id = priority['document-id']\n",
    "                    if isinstance(doc_id, dict):\n",
    "                        country = doc_id.get('country', {}).get('$', '')\n",
    "                        number = doc_id.get('doc-number', {}).get('$', '')\n",
    "                        date = doc_id.get('date', {}).get('$', '')\n",
    "                        if country == 'DE' and number and date:\n",
    "                            priorities.append(f\"{country}{number}¬∑{date}\")\n",
    "    \n",
    "    # Extract title\n",
    "    title_data = find_recursive(ops_data, ['invention-title'])\n",
    "    title = ''\n",
    "    for title_section in title_data:\n",
    "        if isinstance(title_section, list):\n",
    "            for title_item in title_section:\n",
    "                if isinstance(title_item, dict):\n",
    "                    # Prefer English title\n",
    "                    if title_item.get('@lang') == 'en':\n",
    "                        title = title_item.get('$', title_item.get('#text', ''))\n",
    "                        break\n",
    "                    elif not title:  # Fallback to first available\n",
    "                        title = title_item.get('$', title_item.get('#text', ''))\n",
    "    \n",
    "    # Extract IPC classifications\n",
    "    classification_data = find_recursive(ops_data, ['classification-ipc'])\n",
    "    ipc_classes = []\n",
    "    for class_section in classification_data:\n",
    "        if isinstance(class_section, list):\n",
    "            for classification in class_section:\n",
    "                if isinstance(classification, dict) and 'text' in classification:\n",
    "                    ipc_text = classification['text'].get('$', classification['text'].get('#text', ''))\n",
    "                    if ipc_text:\n",
    "                        # Clean up IPC formatting\n",
    "                        clean_ipc = re.sub(r'\\s+', '', ipc_text)\n",
    "                        if clean_ipc not in ipc_classes:\n",
    "                            ipc_classes.append(clean_ipc)\n",
    "    \n",
    "    return {\n",
    "        'applicants': applicants,\n",
    "        'inventors': inventors,\n",
    "        'german_priorities': priorities,\n",
    "        'title': title,\n",
    "        'ipc_classes': ipc_classes\n",
    "    }\n",
    "\n",
    "def categorize_applicants(applicants):\n",
    "    \"\"\"Categorize applicants as University or Industry/Other\"\"\"\n",
    "    university_terms = ['university', 'universit√§t', 'technische', 'hochschule', 'college', 'institut']\n",
    "    categorized = []\n",
    "    \n",
    "    for applicant in applicants:\n",
    "        app_lower = applicant.lower()\n",
    "        if any(term in app_lower for term in university_terms):\n",
    "            categorized.append({'applicant': applicant, 'type': 'University'})\n",
    "        else:\n",
    "            categorized.append({'applicant': applicant, 'type': 'Industry/Other'})\n",
    "    \n",
    "    return categorized\n",
    "\n",
    "def normalize_filename(filename):\n",
    "    \"\"\"Create safe filename from university name\"\"\"\n",
    "    # Replace problematic characters\n",
    "    safe_name = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
    "    safe_name = re.sub(r'\\s+', '_', safe_name)\n",
    "    safe_name = safe_name.strip('_')\n",
    "    return safe_name\n",
    "\n",
    "def generate_pdf_report(university_name, analysis_data, output_dir):\n",
    "    \"\"\"Generate professional PDF report\"\"\"\n",
    "    safe_name = normalize_filename(university_name)\n",
    "    pdf_path = f\"{output_dir}/{safe_name}_analysis_report.pdf\"\n",
    "    \n",
    "    doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = []\n",
    "    \n",
    "    # Title\n",
    "    title_style = ParagraphStyle('CustomTitle', fontSize=16, spaceAfter=30, alignment=1, textColor=colors.darkblue)\n",
    "    story.append(Paragraph(f\"Patent Portfolio Analysis: {university_name}\", title_style))\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Executive Summary\n",
    "    story.append(Paragraph(\"Executive Summary\", styles['Heading2']))\n",
    "    summary_text = f\"\"\"\n",
    "    This report presents a comprehensive analysis of {university_name}'s patent portfolio based on EPO OPS data.\n",
    "    The analysis includes {len(analysis_data)} patents with complete bibliographic information,\n",
    "    industry collaboration mapping, and strategic insights for patent intelligence purposes.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(summary_text, styles['Normal']))\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Key Metrics\n",
    "    story.append(Paragraph(\"Key Metrics\", styles['Heading2']))\n",
    "    metrics_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Total Patents Analyzed', str(len(analysis_data))],\n",
    "        ['Data Source', 'EPO OPS API'],\n",
    "        ['Analysis Date', datetime.now().strftime('%Y-%m-%d')],\n",
    "        ['Methodology', 'Comprehensive bibliographic enrichment']\n",
    "    ]\n",
    "    \n",
    "    metrics_table = Table(metrics_data)\n",
    "    metrics_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "    ]))\n",
    "    \n",
    "    story.append(metrics_table)\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Patent Sample\n",
    "    story.append(Paragraph(\"Representative Patent Sample\", styles['Heading2']))\n",
    "    for i, patent in enumerate(analysis_data[:5], 1):\n",
    "        story.append(Paragraph(f\"Patent {i}: {patent.get('ep_patent', 'N/A')}\", styles['Heading3']))\n",
    "        story.append(Paragraph(f\"Title: {patent.get('title', 'N/A')[:100]}...\", styles['Normal']))\n",
    "        story.append(Paragraph(f\"Filing Year: {patent.get('filing_year', 'N/A')}\", styles['Normal']))\n",
    "        story.append(Spacer(1, 10))\n",
    "    \n",
    "    doc.build(story)\n",
    "    return pdf_path\n",
    "\n",
    "def perform_university_analysis():\n",
    "    \"\"\"Main analysis function triggered by widget interaction\"\"\"\n",
    "    \n",
    "    # Check if analysis was requested\n",
    "    if 'SELECTED_UNIVERSITY' not in globals():\n",
    "        print(\"‚ö†Ô∏è Please select a university and configure analysis options first!\")\n",
    "        return\n",
    "    \n",
    "    university_name = SELECTED_UNIVERSITY\n",
    "    analysis_types = SELECTED_ANALYSES\n",
    "    max_patents = MAX_PATENTS\n",
    "    create_pdf = CREATE_PDF\n",
    "    \n",
    "    print(f\"üöÄ STARTING ANALYSIS FOR: {university_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìä Analysis types: {', '.join(analysis_types)}\")\n",
    "    print(f\"üìÑ Patent limit: {max_patents}\")\n",
    "    print(f\"üïê Started: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    # Load DeepTechFinder data\n",
    "    try:\n",
    "        df = pd.read_csv('./data/EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv', encoding='latin-1')\n",
    "        university_patents = df[df['University'] == university_name].head(max_patents)\n",
    "        \n",
    "        if len(university_patents) == 0:\n",
    "            print(f\"‚ùå No patents found for {university_name}\")\n",
    "            return\n",
    "            \n",
    "        print(f\"üìÑ Found {len(university_patents)} patents for analysis\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize EPO OPS client\n",
    "    ops_client = EPOOPSClient()\n",
    "    if not ops_client.get_access_token():\n",
    "        print(\"‚ùå Failed to authenticate with EPO OPS\")\n",
    "        return\n",
    "    \n",
    "    # Process patents\n",
    "    analysis_results = []\n",
    "    successful_retrievals = 0\n",
    "    \n",
    "    for idx, (_, patent) in enumerate(university_patents.iterrows(), 1):\n",
    "        ep_number = patent['Espacenet_link'].split('=')[-1] if 'espacenet' in patent['Espacenet_link'].lower() else None\n",
    "        \n",
    "        if not ep_number:\n",
    "            continue\n",
    "            \n",
    "        print(f\"üîç Processing {idx}/{len(university_patents)}: {ep_number}\")\n",
    "        \n",
    "        # Get EPO OPS data using the working method\n",
    "        ops_data = ops_client.get_application_biblio(ep_number)\n",
    "        \n",
    "        if ops_data:\n",
    "            bibliographic_data = extract_bibliographic_data(ops_data)\n",
    "            \n",
    "            # Combine with original data\n",
    "            result = {\n",
    "                'ep_patent': ep_number,\n",
    "                'filing_year': patent['Filing_year'],\n",
    "                'patent_status': patent['Patent_status'],\n",
    "                'technical_field': patent['Technical_field'],\n",
    "                'title': bibliographic_data.get('title', patent['Application_title']),\n",
    "                'applicants': bibliographic_data.get('applicants', []),\n",
    "                'inventors': bibliographic_data.get('inventors', []),\n",
    "                'german_priorities': bibliographic_data.get('german_priorities', []),\n",
    "                'ipc_classes': bibliographic_data.get('ipc_classes', [])\n",
    "            }\n",
    "            \n",
    "            analysis_results.append(result)\n",
    "            successful_retrievals += 1\n",
    "            print(f\"‚úÖ Retrieved data for {ep_number}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to retrieve data for {ep_number}\")\n",
    "        \n",
    "        # Rate limiting - EPO OPS requirement\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(f\"\\nüìä ANALYSIS COMPLETED\")\n",
    "    print(f\"‚úÖ Successfully processed: {successful_retrievals}/{len(university_patents)} patents\")\n",
    "    print(f\"üìà Success rate: {successful_retrievals/len(university_patents)*100:.1f}%\")\n",
    "    \n",
    "    if successful_retrievals == 0:\n",
    "        print(\"‚ùå No patent data retrieved. Analysis cannot continue.\")\n",
    "        return\n",
    "    \n",
    "    # Generate outputs based on selected analysis types\n",
    "    safe_name = normalize_filename(university_name)\n",
    "    output_dir = './output'\n",
    "    \n",
    "    # Complete analysis\n",
    "    if 'complete' in analysis_types:\n",
    "        complete_df = pd.DataFrame(analysis_results)\n",
    "        complete_path = f\"{output_dir}/{safe_name}_complete_analysis.csv\"\n",
    "        complete_df.to_csv(complete_path, index=False)\n",
    "        print(f\"üìÑ Complete analysis saved: {complete_path}\")\n",
    "    \n",
    "    # Applicant analysis\n",
    "    if 'collaboration' in analysis_types:\n",
    "        all_applicants = []\n",
    "        for result in analysis_results:\n",
    "            all_applicants.extend(result['applicants'])\n",
    "        \n",
    "        unique_applicants = list(set(all_applicants))\n",
    "        categorized_applicants = categorize_applicants(unique_applicants)\n",
    "        \n",
    "        applicants_df = pd.DataFrame(categorized_applicants)\n",
    "        applicants_path = f\"{output_dir}/{safe_name}_applicants.csv\"\n",
    "        applicants_df.to_csv(applicants_path, index=False)\n",
    "        print(f\"üë• Applicant analysis saved: {applicants_path}\")\n",
    "        \n",
    "        # Display collaboration insights\n",
    "        university_count = len([a for a in categorized_applicants if a['type'] == 'University'])\n",
    "        industry_count = len([a for a in categorized_applicants if a['type'] == 'Industry/Other'])\n",
    "        \n",
    "        print(f\"\\nü§ù COLLABORATION INSIGHTS:\")\n",
    "        print(f\"   üèõÔ∏è University entities: {university_count}\")\n",
    "        print(f\"   üè≠ Industry partners: {industry_count}\")\n",
    "        print(f\"   üìä Collaboration rate: {len(analysis_results)} patents analyzed\")\n",
    "    \n",
    "    # Priority analysis\n",
    "    if 'priority' in analysis_types:\n",
    "        priority_patents = []\n",
    "        for result in analysis_results:\n",
    "            if result['german_priorities']:\n",
    "                for priority in result['german_priorities']:\n",
    "                    priority_patents.append({\n",
    "                        'ep_patent': result['ep_patent'],\n",
    "                        'german_priority': priority,\n",
    "                        'applicants': result['applicants']\n",
    "                    })\n",
    "        \n",
    "        if priority_patents:\n",
    "            priority_df = pd.DataFrame(priority_patents)\n",
    "            priority_path = f\"{output_dir}/{safe_name}_german_priorities.csv\"\n",
    "            priority_df.to_csv(priority_path, index=False)\n",
    "            print(f\"üá©üá™ Priority analysis saved: {priority_path}\")\n",
    "            \n",
    "            priority_rate = len(priority_patents) / len(analysis_results) * 100\n",
    "            print(f\"   üìà German priority rate: {priority_rate:.1f}%\")\n",
    "        else:\n",
    "            print(\"   ‚ÑπÔ∏è No German priorities found in analyzed patents\")\n",
    "    \n",
    "    # Inventor analysis\n",
    "    if 'inventors' in analysis_types:\n",
    "        all_inventors = []\n",
    "        for result in analysis_results:\n",
    "            all_inventors.extend(result['inventors'])\n",
    "        \n",
    "        unique_inventors = list(set(all_inventors))\n",
    "        inventors_df = pd.DataFrame({'inventor': unique_inventors})\n",
    "        inventors_path = f\"{output_dir}/{safe_name}_inventors.csv\"\n",
    "        inventors_df.to_csv(inventors_path, index=False)\n",
    "        print(f\"üî¨ Inventor analysis saved: {inventors_path}\")\n",
    "        print(f\"   üë®‚Äçüî¨ Unique inventors: {len(unique_inventors)}\")\n",
    "    \n",
    "    # Technology analysis\n",
    "    if 'technology' in analysis_types:\n",
    "        all_ipc = []\n",
    "        for result in analysis_results:\n",
    "            all_ipc.extend(result['ipc_classes'])\n",
    "        \n",
    "        if all_ipc:\n",
    "            unique_ipc = list(set(all_ipc))\n",
    "            print(f\"\\nüî¨ TECHNOLOGY PORTFOLIO:\")\n",
    "            print(f\"   üìö IPC classifications: {len(unique_ipc)}\")\n",
    "            print(f\"   üéØ Top classes: {', '.join(unique_ipc[:5])}\")\n",
    "    \n",
    "    # Generate PDF report\n",
    "    if create_pdf and analysis_results:\n",
    "        try:\n",
    "            pdf_path = generate_pdf_report(university_name, analysis_results, output_dir)\n",
    "            print(f\"üìã PDF report generated: {pdf_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è PDF generation failed: {e}\")\n",
    "    \n",
    "    print(f\"\\nüéØ ANALYSIS SUMMARY FOR {university_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"‚úÖ Patents processed: {successful_retrievals}\")\n",
    "    print(f\"üìä Data quality: {successful_retrievals/len(university_patents)*100:.1f}% retrieval success\")\n",
    "    print(f\"üïê Completed: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"üìÅ All results saved to: {output_dir}/\")\n",
    "    \n",
    "    if successful_retrievals > 0:\n",
    "        print(f\"\\nüí° Ready for further analysis with complete bibliographic data!\")\n",
    "        print(f\"üîç Methodology validated and scalable to full portfolio\")\n",
    "\n",
    "# Check if analysis was requested and run it\n",
    "if 'SELECTED_UNIVERSITY' in globals():\n",
    "    perform_university_analysis()\n",
    "else:\n",
    "    print(\"‚úÖ EPO OPS Analysis Module Loaded\")\n",
    "    print(\"üìã Configure analysis options above and click 'Start Analysis' to proceed\")\n",
    "    print(\"üîß All analysis functions ready for execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
